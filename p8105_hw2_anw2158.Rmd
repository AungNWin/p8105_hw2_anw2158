---
title: "p8105_hw2_anw2158"
author: "Aung Nay Win"
date: "2023-10-04"
output: html_document
---

### Problem 0

```{r load_libraries}
library(tidyverse)
library(readxl)
```

### Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r}
snp = 
  read_csv(
    "./fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close)
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r}
unemployment = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

### Problem 2

Read and clean Mr. Trash Wheel data

```{r}
mr_trash_wheel = read_excel("Trash Wheel Collection Data .xlsx")
colnames(mr_trash_wheel) =
  c("Date", "Location", "Trash_Collected_lb", "Plastic_Collected_lb", "Homes_Powered", "Notes", "Cigarette_Butts_Collected")
mr_trash_wheel = mr_trash_wheel[complete.cases(mr_trash_wheel[, 1:3]), ]
```

Calculate Homes Powered:

```{r}
mr_trash_wheel$Trash_Collected_lb = as.numeric(mr_trash_wheel$Trash_Collected_lb)

mr_trash_wheel$Homes_Powered = mr_trash_wheel$Trash_Collected_lb * 0.015
```


Import, Clean, and Organize Professor Trash Wheel

```{r}
professor_trash_wheel = read_excel("Trash Wheel Collection Data .xlsx")
colnames(professor_trash_wheel) =
  c("Date", "Location", "Trash_Collected_lb", "Plastic_Collected_lb", "Homes_Powered", "Notes", "Cigarette_Butts_Collected")
professor_trash_wheel = professor_trash_wheel[complete.cases(professor_trash_wheel[, 1:3]), ]
```

Import, Clean, and Organize Gwynnda Trash Wheel

```{r}
gwynnda_trash_wheel = read_excel("Trash Wheel Collection Data .xlsx")
colnames(gwynnda_trash_wheel) = 
  c("Date", "Location", "Trash_Collected_lb", "Plastic_Collected_lb", "Homes_Powered", "Notes", "Cigarette_Butts_Collected")
gwynnda_trash_wheel = gwynnda_trash_wheel[complete.cases(gwynnda_trash_wheel[, 1:3]), ]
```

Combine Data and Add Identifier Variable

```{r}
mr_trash_wheel$Trash_Collected_lb = as.numeric(mr_trash_wheel$Trash_Collected_lb)
professor_trash_wheel$Trash_Collected_lb = as.numeric(professor_trash_wheel$Trash_Collected_lb)
gwynnda_trash_wheel$Trash_Collected_lb <- as.numeric(gwynnda_trash_wheel$Trash_Collected_lb)


mr_trash_wheel$Trash_Wheel = "Mr. Trash Wheel"
professor_trash_wheel$Trash_Wheel = "Professor Trash Wheel"
gwynnda_trash_wheel$Trash_Wheel = "Gwynnda Trash Wheel"

all_trash_data = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)
```

The dataset, created by combining data from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel, provides a comprehensive overview of trash collection efforts and their environmental impact. It contains a total of nrow(all_trash_data) observations, making it a valuable resource for analysis. Key variables in this dataset include 'Date,' which records the collection date; 'Location,' specifying where the trash was collected; 'Trash_Collected_lb,' denoting the total pounds of trash collected; and 'Homes_Powered,' which approximates the number of homes powered by the energy generated, a vital measure of their eco-friendly operations. The 'Trash_Wheel' variable helps identify the source of the data, distinguishing between the three Trash Wheels. Researchers and environmental enthusiasts can use this dataset to examine trends in trash collection, energy generation, and the environmental impact of these innovative initiatives, ultimately contributing to a cleaner and more sustainable urban environment.

Total weight of trash collected by Professor Trash Wheel

```{r}
total_trash_professor = sum(professor_trash_wheel$Trash_Collected_lb)
```

Total number of cigarette butts collected by Gwynnda in July 2021

```{r}
total_butts_gwynnda_july =
  sum(gwynnda_trash_wheel$Cigarette_Butts_Collected[gwynnda_trash_wheel$Date >= "2021-07-01" & gwynnda_trash_wheel$Date <= "2021-07-31"])
```

### Problem 3

Import the demographic data

```{r}
demographic_df = 
  read.csv("data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(
    sex = recode(sex, "1" = "male" , "0" = "female"),
    apoe4 = recode(apoe4, "1" = "carrier" , "0" = "non-carrier")
  )

```

Filter out participants who do not meet the inclusion criteria (no MCI at baseline)

```{r}
demographic_ = demographic_df %>%
  subset(current_age < age_at_onset | age_at_onset == ".")
```

Summary statistics

people who meet requirements
```{r}
demographic_meet = demographic_df |>
  subset(current_age < age_at_onset | age_at_onset == ".") |>
  mutate(age_at_onset = ifelse(age_at_onset == "." , NA , age_at_onset))
#cleaned
cleaned_demographic = demographic_meet |>
  drop_na()
```

average baseline age
```{r}
mean(demographic_meet$current_age)
print(mean)
```

proportion of women in the study are APOE4 carriers
```{r}
fc=
  sum(demographic_meet$apoe4 == "carrier" & demographic_meet$sex == "female")
f=
  sum(demographic_meet$sex == "female")
print(fc/f) * 100
```

Import the biomarker data

```{r}
biomarker_df = 
  read_csv("data_mci/mci_amyloid.csv" , skip = 1) |>
  janitor::clean_names() 
```

Check for duplicate participants in both demographic and biomarker datasets

```{r}
participants_demographic = unique(demographic_df$id)
participants_biomarker = unique(biomarker_df$study_id)
```

Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained

```{r}
library(dplyr)
demographic_meet = demographic_meet |>
  rename(study_id = id)
view(demographic_meet)
```

```{r}
merge_mci = merge(demographic_meet, biomarker_df, by = "study_id")
```

```{r}
write.csv(merge_mci, "p8105_hw2_anw2158", row.names = FALSE)
```
